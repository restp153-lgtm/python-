import streamlit as st
import pandas as pd
import os

# --------------------------
# --- 1. è³‡æ–™è¼‰å…¥èˆ‡é è™•ç† (é©æ‡‰ Streamlit) ---
# --------------------------

# å°‡ Tabulate å‡½å¼åŒ…è£èµ·ä¾†ï¼Œä»¥ä¾¿åœ¨ Streamlit ä¸­é¡¯ç¤º
def format_results_for_streamlit(results):
    if not results:
        return pd.DataFrame()
        
    table_headers = [
        "åæ¬¡", "æ·é‹ç«™", "æ™¯é»åç¨±", "ç¸½åˆ†", 
        "Tagåˆ†æ•¸(0.4)", "Walkåˆ†æ•¸(0.3)", "Priceåˆ†æ•¸(0.2)", "Ratingåˆ†æ•¸(0.1)"
    ]
    
    table_rows = []
    for item in results:
        table_rows.append({
            "åæ¬¡": item['rank'],
            "æ·é‹ç«™": item['mrt_station'],
            "æ™¯é»åç¨±": item['name'],
            "ç¸½åˆ†": f"{item['total_score']:.4f}",
            "Tagåˆ†æ•¸(0.4)": f"{item['score_tag']:.4f}",
            "Walkåˆ†æ•¸(0.3)": f"{item['score_walk']:.4f}",
            "Priceåˆ†æ•¸(0.2)": f"{item['score_price']:.4f}",
            "Ratingåˆ†æ•¸(0.1)": f"{item['score_rating']:.4f}",
        })
    
    return pd.DataFrame(table_rows, columns=table_headers)


@st.cache_data
def load_and_preprocess_data():
    """è¼‰å…¥ CSV æª”æ¡ˆä¸¦é€²è¡Œå¿…è¦çš„è³‡æ–™æ¸…ç†èˆ‡è½‰æ›ã€‚"""
    
    encoding_list = ['utf-8', 'cp950'] 
    
    def try_read_csv(filename):
        for encoding in encoding_list:
            try:
                if not os.path.exists(filename):
                    raise FileNotFoundError(f"æª”æ¡ˆä¸å­˜åœ¨: {filename}")
                return pd.read_csv(filename, encoding=encoding)
            except UnicodeDecodeError:
                continue 
            except FileNotFoundError:
                raise 
        raise UnicodeDecodeError(f"ç„¡æ³•ä½¿ç”¨æ”¯æ´çš„ç·¨ç¢¼ ({', '.join(encoding_list)}) è®€å–æª”æ¡ˆ: {filename}")

    # --- è¼‰å…¥å€å¡Š ---
    try:
        # 1. è¼‰å…¥æ·é‹äº¤é€šæ™‚é–“ (Mrt Time)
        mrt_time_df = try_read_csv('æ·é‹äº¤é€šæ™‚é–“.csv')
        mrt_time_df = mrt_time_df.set_index(mrt_time_df.columns[0])
        mrt_time_db = mrt_time_df.to_dict(orient='index')
        mrt_stations = list(mrt_time_df.index)
        
        # 2. è¼‰å…¥æ™¯é»è³‡æ–™ (Attraction)
        attraction_df = try_read_csv('æ™¯é».csv')
        
        # --- é è™•ç†å€å¡Š ---
        attraction_df['walk_min'] = pd.to_numeric(attraction_df['walk_min'], errors='coerce')
        attraction_df['rating'] = pd.to_numeric(attraction_df['rating'], errors='coerce')
        
        # è™•ç† tags (ä½¿ç”¨åˆ†è™Ÿ ';' åˆ†éš”)
        attraction_df['tags'] = attraction_df['tags'].astype(str).apply(lambda x: x.split(';') if ';' in x else [x])
        
        attraction_df.dropna(subset=['walk_min', 'rating'], inplace=True)
        
        return mrt_time_db, attraction_df, mrt_stations

    except Exception as e:
        st.error(f"è³‡æ–™è¼‰å…¥æˆ–è™•ç†å¤±æ•—: {e}. è«‹æª¢æŸ¥æ‚¨çš„ CSV æª”æ¡ˆåç¨±å’Œç·¨ç¢¼ã€‚")
        return None, None, None

# ----------------------------------------
# --- 2. Step 1: æœ€å…¬å¹³æœƒåˆæ·é‹ç«™ (Min-Max) ---
# ----------------------------------------

def find_fair_mrt_station(user_starts, mrt_time_db, all_stations):
    """
    å¯¦ä½œ Min-Max å…¬å¹³æ¼”ç®—æ³•ï¼Œæ‰¾å‡ºæœ€å…¬å¹³çš„æœƒåˆæ·é‹ç«™ã€‚
    """
    max_time_table = {}
    
    for target_station in all_stations:
        max_travel_time = 0
        for start_station in user_starts:
            time = mrt_time_db.get(start_station, {}).get(target_station)
            
            if time is None:
                max_travel_time = float('inf') 
                break 
            
            if time > max_travel_time:
                max_travel_time = time
        
        max_time_table[target_station] = max_travel_time

    if not max_time_table or all(v == float('inf') for v in max_time_table.values()):
        return [], 0
        
    min_max_time = min(max_time_table.values())

    fair_stations = [
        station for station, max_time in max_time_table.items() 
        if max_time == min_max_time
    ]
    
    return fair_stations, min_max_time

# ----------------------------------------
# --- 3. Step 2: æ™¯é»åŠ æ¬Šåˆ†æ•¸è¨ˆç®—èˆ‡æ’åº ---
# ----------------------------------------

def calculate_attraction_score(candidate_df, user_tags, num_users):
    """
    è¨ˆç®—æ™¯é»çš„åŠ æ¬Šåˆ†æ•¸ä¸¦æ’åºã€‚
    """
    
    # æ¬Šé‡è¨­å®š
    WEIGHT_TAGS = 0.4
    WEIGHT_WALK = 0.3
    WEIGHT_PRICE = 0.2
    WEIGHT_RATING = 0.1
    
    # --- 1. tagsæ¨™ç±¤åˆ†æ•¸ (æ¬Šé‡ * 0.4) ---
    def get_tag_match_score(attraction_tags):
        match_count = 0
        for tag in attraction_tags:
            match_count += user_tags.count(tag) 
        return match_count / num_users
    
    candidate_df['score_tag'] = candidate_df['tags'].apply(get_tag_match_score)
    
    # --- 2. walk_min èµ°è·¯æ™‚é•·åˆ†æ•¸ (æ¬Šé‡ * 0.3) ---
    MIN_WALK = 2
    MAX_WALK = 13
    WALK_RANGE = MAX_WALK - MIN_WALK
    
    candidate_df['score_walk'] = (MAX_WALK - candidate_df['walk_min']) / WALK_RANGE
    candidate_df.loc[candidate_df['walk_min'] <= MIN_WALK, 'score_walk'] = 1.0
    candidate_df.loc[candidate_df['walk_min'] >= MAX_WALK, 'score_walk'] = 0.0
    
    # --- 3. price_level åƒ¹æ ¼åˆ†æ•¸ (æ¬Šé‡ * 0.2) ---
    price_map = {'low': 1.0, 'medium': 0.5, 'high': 0.0}
    
    def get_price_score(price_level_str):
        levels = str(price_level_str).lower().split(';')
        return max(price_map.get(level, 0.0) for level in levels) if levels else 0.0
        
    candidate_df['score_price'] = candidate_df['price_level'].apply(get_price_score)
    
    # --- 4. rating è©•åƒ¹åˆ†æ•¸ (æ¬Šé‡ * 0.1) ---
    candidate_df['score_rating'] = candidate_df['rating'] / 5.0
    
    # --- 5. è¨ˆç®—ç¸½åˆ† (åŠ æ¬Šå’Œ) ---
    candidate_df['total_score'] = (
        candidate_df['score_tag'] * WEIGHT_TAGS +
        candidate_df['score_walk'] * WEIGHT_WALK +
        candidate_df['score_price'] * WEIGHT_PRICE +
        candidate_df['score_rating'] * WEIGHT_RATING
    )
    
    # æ’åº
    final_recommendations_df = candidate_df.sort_values(
        by='total_score', ascending=False
    ).reset_index(drop=True)
    
    final_recommendations_df['rank'] = final_recommendations_df.index + 1
    
    return final_recommendations_df.to_dict('records')


# --------------------------
# --- 4. Streamlit ä»‹é¢ ---
# --------------------------

def app():
    st.set_page_config(page_title="ç´„æœƒåœ°é»æ¨è–¦ç³»çµ±", layout="wide")
    st.title("ğŸ’– ç´„æœƒåœ°é»æ¨è–¦ç³»çµ± (Min-Max å…¬å¹³æ¼”ç®—æ³•)")
    st.markdown("---")

    # è¼‰å…¥è³‡æ–™ (ä½¿ç”¨ Streamlit cache é¿å…é‡è¤‡è®€å–)
    mrt_time_db, attraction_df, mrt_stations = load_and_preprocess_data()
    
    if mrt_time_db is None:
        st.stop() # å¦‚æœè³‡æ–™è¼‰å…¥å¤±æ•—ï¼Œå‰‡åœæ­¢åŸ·è¡Œ
    
    VALID_TAGS = ['æ™¯é»', 'æ•£æ­¥', 'çœ‹å±•', 'å’–å•¡å»³', 'é€›è¡—', 'é›»å½±', 'æ‰‹ä½œ', 'å¤œå¸‚']
    
    # --- å´é‚Šæ¬„è¼¸å…¥å€ ---
    with st.sidebar:
        st.header("ğŸ‘¥ ä½¿ç”¨è€…è¼¸å…¥")
        
        # 1. ç¸½äººæ•¸ N
        N = st.slider("è«‹è¼¸å…¥ç¸½äººæ•¸ N (2~10)", min_value=2, max_value=10, value=3)
        
        user_inputs = []
        for i in range(1, N + 1):
            st.subheader(f"ä½¿ç”¨è€… {i}")
            
            # 2. å‡ºç™¼æ·é‹ç«™ (ä½¿ç”¨ selectbox æ–¹ä¾¿é¸æ“‡)
            start_station = st.selectbox(
                f"è«‹é¸æ“‡ä½¿ç”¨è€… {i} çš„å‡ºç™¼æ·é‹ç«™:", 
                options=mrt_stations, 
                key=f"start_{i}"
            )
            
            # 3. åå¥½æ¨™ç±¤
            preference_tag = st.selectbox(
                f"è«‹é¸æ“‡ä½¿ç”¨è€… {i} çš„åå¥½æ¨™ç±¤:", 
                options=VALID_TAGS, 
                key=f"tag_{i}"
            )
            
            user_inputs.append({
                "start": start_station,
                "tag": preference_tag
            })

    # --- ä¸»å€åŸŸçµæœå±•ç¤º ---
    if st.button("ğŸš€ å•Ÿå‹•æ¨è–¦!"):
        if not user_inputs:
            st.warning("è«‹åœ¨å´é‚Šæ¬„è¼¸å…¥ä½¿ç”¨è€…è³‡è¨Šã€‚")
            return

        # æº–å‚™ Step 1 è¼¸å…¥è³‡æ–™
        user_starts = [u['start'] for u in user_inputs]
        user_tags = [u['tag'] for u in user_inputs]
        
        # --- Step 1: æ‰¾å‡ºæœ€å…¬å¹³æœƒåˆç«™ ---
        st.header("1ï¸âƒ£ Step 1: æœ€å…¬å¹³æœƒåˆæ·é‹ç«™ (Min-Max)")
        
        fair_stations, min_max_time = find_fair_mrt_station(user_starts, mrt_time_db, mrt_stations)
        
        if not fair_stations:
            st.error("ç„¡æ³•è¨ˆç®—å‡ºå…¬å¹³æœƒé¢åœ°é»ã€‚è«‹æª¢æŸ¥æ·é‹ç«™è³‡æ–™ã€‚")
            return

        st.success(f"ğŸ‰ **æœ€å…¬å¹³æœƒé¢åœ°é»**: **{', '.join(fair_stations)}**")
        st.info(f"ğŸ•°ï¸ **æœ€é•·é€šå‹¤æ™‚é–“**: **{min_max_time} åˆ†é˜**")

        # --- Step 2: ç¯©é¸æ™¯é»ä¸¦è¨ˆç®—åˆ†æ•¸ ---
        st.header("2ï¸âƒ£ Step 2: æ™¯é»åŠ æ¬Šåˆ†æ•¸è¨ˆç®—èˆ‡æ’åº")
        
        candidate_attractions_df = attraction_df[
            attraction_df['mrt_station'].isin(fair_stations)
        ].copy() 
        
        if candidate_attractions_df.empty:
            st.warning(f"æœ€å…¬å¹³æœƒé¢åœ°é»é™„è¿‘æ²’æœ‰æ¨è–¦æ™¯é»ã€‚")
            return

        final_recommendations = calculate_attraction_score(candidate_attractions_df, user_tags, N)

        # æ ¼å¼åŒ–ä¸¦é¡¯ç¤ºçµæœ
        results_df = format_results_for_streamlit(final_recommendations)
        
        st.subheader("ğŸ” æ¨è–¦æ™¯é»æ’å (åŠ æ¬Šç¸½åˆ†è¨ˆç®—)")
        st.dataframe(results_df, use_container_width=True)
        
        st.markdown("---")
        st.balloons() # åŠ çˆ½çš„
        st.success("ğŸ’– ä»¥ä¸Šæ˜¯æ¨è–¦çš„ç›®çš„åœ° ç¥å„ä½ç´„æœƒé–‹å¿ƒ! ğŸ’–")

if __name__ == '__main__':
    app()